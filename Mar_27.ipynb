{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be32095-3737-4c9b-9578-a8b356270b88",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070bcd17-9134-4496-8281-407456cda00a",
   "metadata": {},
   "source": [
    "## Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?\n",
    "\n",
    "Ans: R-squared in linear regression models:\n",
    "\n",
    "- R-squared (R²) represents the proportion of variance in the dependent variable that is explained by the independent variables in a linear regression model.\n",
    "- It is calculated as the ratio of the explained variance to the total variance.\n",
    "- R² ranges from 0 to 1, where 0 means the model explains none of the variance, and 1 means the model perfectly explains the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b858d-75da-41c1-a6d5-e488d0ab877c",
   "metadata": {},
   "source": [
    "## Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "\n",
    "Ans: Adjusted R-squared:\n",
    "\n",
    "- Adjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in the model.\n",
    "- It penalizes the inclusion of irrelevant predictors, preventing inflation of R-squared when adding more variables.\n",
    "- Adjusted R-squared can be lower than R-squared, and it accounts for the model's complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a4d8f-56e2-48ae-b1b5-74d736985951",
   "metadata": {},
   "source": [
    "## Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "Ans:  When to use adjusted R-squared:\n",
    "\n",
    "- Use adjusted R-squared when comparing models with different numbers of predictors.\n",
    "- It is more appropriate for model selection and prevents overfitting by considering the trade-off between model complexity and fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc7edd-10e8-49bb-8c33-42f518e37b6b",
   "metadata": {},
   "source": [
    "## Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics calculated, and what do they represent?\n",
    "\n",
    "Ans: RMSE, MSE, and MAE in regression analysis:\n",
    "\n",
    "- RMSE (Root Mean Squared Error): It measures the average of squared differences between predicted and actual values.\n",
    "- MSE (Mean Squared Error): It is the average of squared differences between predicted and actual values.\n",
    "- MAE (Mean Absolute Error): It measures the average of absolute differences between predicted and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277c891-0612-49a6-8b57-54722d7524b3",
   "metadata": {},
   "source": [
    "## Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in regression analysis.\n",
    "\n",
    "Ans: Advantages and disadvantages of RMSE, MSE, and MAE:\n",
    "\n",
    "- RMSE and MSE emphasize larger errors, which can be useful for some applications.\n",
    "- MAE is less sensitive to outliers compared to RMSE and MSE.\n",
    "- RMSE and MSE can be sensitive to outliers.\n",
    "- MAE provides a linear penalty for errors but might not prioritize larger errors as much as RMSE and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7018db-59ba-4664-b3e3-84011aef3862",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?\n",
    "\n",
    "Ans: Lasso regularization:\n",
    "\n",
    "- Lasso is a regularization technique used to add a penalty term based on the absolute values of the coefficients in the linear regression model.\n",
    "- It can perform feature selection by forcing some coefficients to be exactly zero.\n",
    "- Lasso is suitable when there is a suspicion that only a few predictors are relevant, effectively shrinking less important coefficients to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d7af8-9a89-40c2-9da3-2c6fbdc4737e",
   "metadata": {},
   "source": [
    "## Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an example to illustrate.\n",
    "\n",
    "Ans: Preventing overfitting with regularized linear models:\n",
    "\n",
    "- Regularized linear models add penalty terms to the cost function, discouraging large coefficients.\n",
    "- This prevents the model from fitting noise in the data and helps generalize better to unseen data.\n",
    "- Example: In ridge regression, the L2 penalty adds the square of the coefficients to the cost function, limiting their impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bdcf46-5434-4c91-8915-eca033283c11",
   "metadata": {},
   "source": [
    "## Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis.\n",
    "\n",
    "Ans: Limitations of regularized linear models:\n",
    "\n",
    "- Regularized models can be sensitive to the choice of regularization hyperparameters.\n",
    "- They might not work well if all predictors are equally important or if the relationship between predictors and the target is highly nonlinear.\n",
    "- For some problems, more sophisticated models like decision trees or neural networks might be more suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb1421-0cf7-4f2d-a4ea-121144592bca",
   "metadata": {},
   "source": [
    "## Q9. You are comparing the performance of two regression models using different evaluation metrics. Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better performer, and why? Are there any limitations to your choice of metric?\n",
    "\n",
    "Ans: Model comparison based on evaluation metrics:\n",
    "\n",
    "- Model B with an MAE of 8 is the better performer because it has a smaller error compared to Model A with an RMSE of 10.\n",
    "- MAE is more interpretable and robust to outliers, making it a better choice for comparing models with different characteristics.\n",
    "\n",
    "Limitations: The choice of metric depends on the problem and the specific characteristics of the data. RMSE might be more suitable when larger errors need to be penalized more, or if the data distribution is closer to a normal distribution without significant outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb09355-f32c-4fa0-95e3-f12a1964cad2",
   "metadata": {},
   "source": [
    "## Q10. You are comparing the performance of two regularized linear models using different types of regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the better performer, and why? Are there any trade-offs or limitations to your choice of regularization method?\n",
    "\n",
    "Ans:  Model comparison based on regularization method:\n",
    "\n",
    "- Model B using Lasso regularization with a regularization parameter of 0.5 is the better performer if it has lower prediction errors and more sparse coefficients.\n",
    "- Lasso regularization can perform feature selection by shrinking some coefficients to exactly zero, which might be preferred if there is a suspicion that only a few predictors are relevant.\n",
    "\n",
    "Limitations: The choice of regularization method depends on the problem and the assumptions about the importance of predictors. Ridge regularization (L2 penalty) might be more suitable when all predictors are potentially important, but their coefficients need to be controlled. Lasso can be sensitive to multicollinearity, and the choice between the two methods might require tuning the regularization parameters based on the data and domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da534e7-cef2-4559-bea3-02d8e09ff1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
